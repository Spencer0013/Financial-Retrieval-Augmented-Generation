{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d65b97a",
   "metadata": {},
   "source": [
    "Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e947fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, zipfile, io\n",
    "# from pathlib import Path\n",
    "\n",
    "# zip_url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/fiqa.zip\"\n",
    "# out_dir = Path(\"fiqa\")\n",
    "# out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Download the ZIP into memory (fine for small/medium files)\n",
    "# resp = requests.get(zip_url, timeout=120)\n",
    "# resp.raise_for_status()\n",
    "\n",
    "# # Extract all files\n",
    "# with zipfile.ZipFile(io.BytesIO(resp.content)) as z:\n",
    "#     z.extractall(out_dir)\n",
    "\n",
    "# print(f\"Extracted to: {out_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ed1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecf2a2",
   "metadata": {},
   "source": [
    "Get Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f60ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(path: str) -> Iterable[Dict]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                yield json.loads(line)\n",
    "\n",
    "def record_to_document(rec: Dict, source: str) -> Document:\n",
    "    _id = rec.get(\"_id\")\n",
    "    title = rec.get(\"title\", \"\")\n",
    "    text = rec.get(\"text\", \"\")\n",
    "\n",
    "    if title and title.strip():\n",
    "        content = f\"{title.strip()}\\n\\n{text.strip()}\"\n",
    "    else:\n",
    "        content = text.strip()\n",
    "\n",
    "    meta = {**rec.get(\"metadata\", {})}\n",
    "    meta.update({\n",
    "        \"source\": source,   # 'fiqa_corpus' or 'fiqa_queries'\n",
    "        \"id\": _id,\n",
    "    })\n",
    "    if title:\n",
    "        meta[\"title\"] = title\n",
    "\n",
    "    return Document(page_content=content, metadata=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      \n",
    "    chunk_overlap=200,     \n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  \n",
    ")\n",
    "\n",
    "def preprocess_fiqa_corpus(corpus_path: str) -> List[Document]:\n",
    "    docs = []\n",
    "    for rec in read_jsonl(corpus_path):\n",
    "        doc = record_to_document(rec, source=\"fiqa_corpus\")\n",
    "        docs.append(doc)\n",
    "    # chunk\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "def preprocess_fiqa_queries(queries_path: str) -> List[Document]:\n",
    "    docs = []\n",
    "    for rec in read_jsonl(queries_path):\n",
    "        doc = record_to_document(rec, source=\"fiqa_queries\")\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc1f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = r\"C:\\Users\\ainao\\OneDrive\\Project\\Financial-Retrieval-Augmented-Generation\\fiqa\\corpus.jsonl\"\n",
    "queries_path = r\"C:\\Users\\ainao\\OneDrive\\Project\\Financial-Retrieval-Augmented-Generation\\fiqa\\queries.jsonl\"\n",
    "\n",
    "fiqa_chunked_corpus: List[Document] = preprocess_fiqa_corpus(corpus_path)\n",
    "fiqa_queries: List[Document] = preprocess_fiqa_queries(queries_path)\n",
    "\n",
    "pinecone_docs = fiqa_chunked_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2987cd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'fiqa_corpus', 'id': '3'}, page_content=\"I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.\"),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '31'}, page_content=\"So nothing preventing false ratings besides additional scrutiny from the market/investors, but there are some newer controls in place to prevent institutions from using them. Under the DFA banks can no longer solely rely on credit ratings as due diligence to buy a financial instrument, so that's a plus. The intent being that if financial institutions do their own leg work then *maybe* they'll figure out that a certain CDO is garbage or not.  Edit: lead in\"),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '56'}, page_content=\"You can never use a health FSA for individual health insurance premiums.  Moreover, FSA plan sponsors can limit what they are will to reimburse.  While you can't use a health FSA for premiums, you could previously use a 125 cafeteria plan to pay premiums, but it had to be a separate election from the health FSA. However, under N. 2013-54, even using a cafeteria plan to pay for indivdiual premiums is effectively prohibited.\"),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '59'}, page_content='Samsung created the LCD and other flat screen technology like OLED. a few years ago every flat screen came from Samsung factories and were reshelled. I think the 21 Hanns screen I am looking at now is Samsung and it is only a couple of years old. Samsung seem to be a good company.'),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '63'}, page_content='Here are the SEC requirements: The federal securities laws define the term accredited investor in   Rule 501 of Regulation D as: a bank, insurance company, registered investment company, business development company, or small business investment company; an employee benefit plan, within the meaning of the Employee Retirement Income Security Act, if a bank, insurance company, or   registered investment adviser makes the investment decisions, or if   the plan has total assets in excess of $5 million; a charitable organization, corporation, or partnership with assets exceeding $5 million; a director, executive officer, or general partner of the company selling the securities; a business in which all the equity owners are accredited investors; a natural person who has individual net worth, or joint net worth with the person’s spouse, that exceeds $1 million at the time of the   purchase, excluding the value of the primary residence of such person; a natural person with income exceeding'),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '63'}, page_content='or joint net worth with the person’s spouse, that exceeds $1 million at the time of the   purchase, excluding the value of the primary residence of such person; a natural person with income exceeding $200,000 in each of the two most recent years or joint income with a spouse exceeding $300,000 for   those years and a reasonable expectation of the same income level in   the current year; or a trust with assets in excess of $5 million, not formed to acquire the securities offered, whose purchases a sophisticated person makes. No citizenship/residency requirements.'),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '100'}, page_content='\"Only relevant to those with fantasy economy teams. Seriously, Rand\\'s fictional works never translate well into reality because, no matter how hard people try, that \"\"fiction\"\" element just can\\'t be ignored.  Test it yourself: Strip John Galt and his followers of everything they have which was created by or within the \"\"society\"\" they so revile, drop them in the desert -- and they\\'ll all be dead of exposure and starvation in less than two weeks because they will be naked, without tools and without food.  The only reason the libertarians get away with pushing their tripe as a rational philosophy is because no one will point out what it is wrong with their thinking. Why? Well, for most of my lifetime, their \"\"philosophy\"\" was considered nuttery in line with the John Birchers and so why bother. It\\'s only with the ascendency of these billionaire-funded politicians that this crap thinking has become acceptable, and even then, only to them.\"'),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '108'}, page_content='Futures contracts are a member of a larger class of financial assets called derivatives. Derivatives are called such because their payoffs depend on the price of other assets (financial or real). Other kinds of derivatives are call options, put options. Fixed income assets that mimic the behavior of derivatives are callable bonds, puttable bonds etc.  A futures contract is a contract that specifies the following: Just like with any other contract, there are two parties involved. One party commits to delivering the underlying asset to the other party on expiration date in exchange for the futures price. The other party commits to paying the futures price in exchange for the asset. There is no price that any of the two parties pay upfront to engage in the contract. The language used is so that the agent committing to receiving the delivery of the underlying asset is said to have bought the contract. The agent that commits to make the delivery is said to have sold the contract.  So answer'),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '108'}, page_content=\"the agent committing to receiving the delivery of the underlying asset is said to have bought the contract. The agent that commits to make the delivery is said to have sold the contract.  So answer your question, buying on June 1 a futures contract at the futures price of $100, with a maturity date on August 1 means you commit to paying $100 for the underlying asset on August 1. You don't have to pay anything upfront. Futures price is simply what the contract prescribes the underlying asset will exchange hands for.\"),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '125'}, page_content='This month when you join Scentsy you get a free defuser with your kit!   This has never been done before.  You also get spring / summer and Fall / Winter testers plus all your kit items!    Be your own boss!  You choose what hours you work, when and where you work them.   Join my Scentsy family today!  [Amanda C. Robar Scentsy Business ](http://www.amandacrobar.scentsy.ca)')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a77120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has OPENAI_API_KEY: True\n",
      "Has PINECONE_API_KEY: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "ENV_PATH = Path.cwd() / \"env\" / \".env\" \n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "#load_dotenv(ENV_PATH)   # searches upward from the current working dir\n",
    "print(\"Has OPENAI_API_KEY:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"Has PINECONE_API_KEY:\", bool(os.getenv(\"PINECONE_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf907ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(\n",
    "        api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e22077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ainao\\anaconda3\\envs\\fiqa\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'dotproduct',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"fiqa-hybrid\"\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"dotproduct\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Initialize index client\n",
    "index = pc.Index(name=index_name)\n",
    "\n",
    "# View index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "154727ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.db_data.index.Index at 0x26106418080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416ac4d",
   "metadata": {},
   "source": [
    "Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e73f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ainao\\AppData\\Local\\Temp\\ipykernel_200\\3327527024.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\ainao\\anaconda3\\envs\\fiqa\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ainao\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5adbbe",
   "metadata": {},
   "source": [
    "BM encdoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bc9b4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ainao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x26156020260>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "\n",
    "bm25_encoder = BM25Encoder().default()\n",
    "bm25_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9b09a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'fiqa_corpus', 'id': '3'}, page_content=\"I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.\"),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '31'}, page_content=\"So nothing preventing false ratings besides additional scrutiny from the market/investors, but there are some newer controls in place to prevent institutions from using them. Under the DFA banks can no longer solely rely on credit ratings as due diligence to buy a financial instrument, so that's a plus. The intent being that if financial institutions do their own leg work then *maybe* they'll figure out that a certain CDO is garbage or not.  Edit: lead in\"),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '56'}, page_content=\"You can never use a health FSA for individual health insurance premiums.  Moreover, FSA plan sponsors can limit what they are will to reimburse.  While you can't use a health FSA for premiums, you could previously use a 125 cafeteria plan to pay premiums, but it had to be a separate election from the health FSA. However, under N. 2013-54, even using a cafeteria plan to pay for indivdiual premiums is effectively prohibited.\"),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '59'}, page_content='Samsung created the LCD and other flat screen technology like OLED. a few years ago every flat screen came from Samsung factories and were reshelled. I think the 21 Hanns screen I am looking at now is Samsung and it is only a couple of years old. Samsung seem to be a good company.'),\n",
       " Document(metadata={'source': 'fiqa_corpus', 'id': '63'}, page_content='Here are the SEC requirements: The federal securities laws define the term accredited investor in   Rule 501 of Regulation D as: a bank, insurance company, registered investment company, business development company, or small business investment company; an employee benefit plan, within the meaning of the Employee Retirement Income Security Act, if a bank, insurance company, or   registered investment adviser makes the investment decisions, or if   the plan has total assets in excess of $5 million; a charitable organization, corporation, or partnership with assets exceeding $5 million; a director, executive officer, or general partner of the company selling the securities; a business in which all the equity owners are accredited investors; a natural person who has individual net worth, or joint net worth with the person’s spouse, that exceeds $1 million at the time of the   purchase, excluding the value of the primary residence of such person; a natural person with income exceeding')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 78139 texts\n",
      "78139\n",
      "78139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "\n",
    "for d in pinecone_docs:\n",
    "    if getattr(d, \"page_content\", None):\n",
    "        t = d.page_content.strip()\n",
    "        if t:\n",
    "            texts.append(t)\n",
    "            metadatas.append(dict(d.metadata or {}))\n",
    "            ids.append(str(d.metadata.get(\"id\", len(ids))))\n",
    "\n",
    "print(f\"Prepared {len(texts)} texts\"), print(f\"{len(metadatas)}\"), print(f\"{len(ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd1631",
   "metadata": {},
   "source": [
    "Encode text documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7aad3432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78139/78139 [01:37<00:00, 803.79it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x26160aeb2f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "\n",
    "bm25_encoder = BM25Encoder().default()\n",
    "bm25_encoder.fit(texts)                 \n",
    "#bm25_encoder.dump(\"bm25_values.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6129dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sparse_list = bm25_encoder.encode_documents(texts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdffb66",
   "metadata": {},
   "source": [
    "Upsert chunked documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e7a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting 78130 / 78139 chunks (non-empty sparse)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2442/2442 [1:42:14<00:00,  2.51s/it]  \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import PineconeHybridSearchRetriever\n",
    "keep_texts, keep_metas, keep_ids = [], [], []\n",
    "for t, sp, m, i_ in zip(texts, doc_sparse_list, metadatas, ids):\n",
    "    if sp and sp.get(\"indices\") and sp.get(\"values\"):\n",
    "        keep_texts.append(t)\n",
    "        keep_metas.append(m)\n",
    "        keep_ids.append(i_)\n",
    "\n",
    "print(f\"Upserting {len(keep_texts)} / {len(texts)} chunks (non-empty sparse)\")\n",
    "\n",
    "retriever = PineconeHybridSearchRetriever(\n",
    "    embeddings=embeddings,\n",
    "    sparse_encoder=bm25_encoder,  # already fitted\n",
    "    index=index\n",
    ")\n",
    "\n",
    "# This will upsert with both dense & sparse values\n",
    "retriever.add_texts(keep_texts, metadatas=keep_metas, ids=keep_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885714d0",
   "metadata": {},
   "source": [
    "Make a RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n",
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SEC requirements for an accredited investor, as defined in Rule 501 of Regulation D, are as follows:\n",
      "\n",
      "1. **Net Worth Criteria**: A natural person must have an individual net worth, or joint net worth with their spouse, that exceeds $1 million at the time of purchase. This calculation excludes the value of the person's primary residence.\n",
      "\n",
      "2. **Income Criteria**: A natural person must have an income exceeding $200,000 per year (or $300,000 together with a spouse) for the last two years, with the expectation of earning the same or a higher income in the current year.\n",
      "\n",
      "3. **Entities**: Certain entities qualify as accredited investors, including:\n",
      "   - Banks, insurance companies, registered investment companies, business development companies, or small business investment companies.\n",
      "   - Employee benefit plans with total assets exceeding $5 million, if a bank, insurance company, or registered investment adviser makes the investment decisions.\n",
      "   - Charitable organizations, corporations, or partnerships with assets exceeding $5 million.\n",
      "   - Directors, executive officers, or general partners of the company selling the securities.\n",
      "   - Businesses in which all equity owners are accredited investors.\n",
      "\n",
      "These regulations are set by the SEC due to the perceived risk associated with certain investments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Forbidden\"}\\n')\n"
     ]
    }
   ],
   "source": [
    "## ChatPrompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "query = \"What are the SEC requirements for an accredited investor?\"\n",
    "result = rag_chain.invoke({\"input\": query})\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
